{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Transformer Model Training (Google Colab版)\n",
        "## 暗号通貨価格予測のためのTransformerモデルトレーニング\n",
        "\n",
        "このNotebookは、Google Colab環境でTransformerモデルを訓練するためのものです。\n",
        "\n",
        "⚠️ **事前準備**\n",
        "1. `google_colab_setup.ipynb`を実行してセットアップを完了してください\n",
        "2. KuCoin APIキーをGoogle ColabのSecretsに設定してください\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Colab環境の設定とライブラリインポート\n",
        "import os\n",
        "\n",
        "# プロジェクトのルートディレクトリに移動\n",
        "if '/content/sakata_goho_chart' not in os.getcwd():\n",
        "    os.chdir('/content/sakata_goho_chart')\n",
        "\n",
        "print(f\"現在のディレクトリ: {os.getcwd()}\")\n",
        "\n",
        "# 必要なライブラリのインポート\n",
        "import sys\n",
        "sys.path.append('.')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# 自作モジュールのインポート\n",
        "from src.data_fetcher import DataFetcher\n",
        "from src.technical_indicators import TechnicalIndicators\n",
        "from src.utils import DataPreprocessor, ModelUtils\n",
        "\n",
        "# Transformerモデル用のライブラリ\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LayerNormalization, Dropout\n",
        "from tensorflow.keras.layers import MultiHeadAttention, GlobalAveragePooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"ライブラリのインポート完了\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データ取得\n",
        "from google.colab import userdata\n",
        "\n",
        "# KuCoin APIの設定\n",
        "fetcher = DataFetcher(\n",
        "    exchange_name='kucoin',\n",
        "    api_key=userdata.get('KuCoin_API_KEY'),\n",
        "    secret=userdata.get('KuCoin_API_SECRET'),\n",
        "    password=userdata.get('KuCoin_API_PASSPHRAS')\n",
        ")\n",
        "\n",
        "# データ取得設定\n",
        "symbol = 'SOL/USDT'\n",
        "timeframe = '1d'\n",
        "limit = 8760 * 2  # 2年分\n",
        "\n",
        "print(f\"データ取得開始: {symbol}\")\n",
        "data = fetcher.fetch_ohlcv_data(symbol, timeframe, limit)\n",
        "\n",
        "if data is not None:\n",
        "    print(f\"取得完了: {len(data)}件\")\n",
        "    print(data.head())\n",
        "    \n",
        "    # Google Driveに保存（バックアップ用）\n",
        "    backup_path = \"/content/drive/MyDrive/trading_bot_data.csv\"\n",
        "    data.to_csv(backup_path)\n",
        "    print(f\"データをGoogle Driveに保存: {backup_path}\")\n",
        "else:\n",
        "    print(\"データ取得に失敗しました。APIキーを確認してください。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# テクニカル指標の追加\n",
        "print(\"テクニカル指標を計算中...\")\n",
        "df = TechnicalIndicators.add_all_indicators(data)\n",
        "print(f\"テクニカル指標追加完了: {df.shape}\")\n",
        "\n",
        "# データの概要を表示\n",
        "print(\"\\nデータの基本統計:\")\n",
        "print(df.describe())\n",
        "\n",
        "# データを可視化\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(df.index, df['Close'])\n",
        "plt.title('Price Chart')\n",
        "plt.ylabel('Price')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(df.index, df['RSI'])\n",
        "plt.title('RSI')\n",
        "plt.ylabel('RSI')\n",
        "plt.axhline(y=70, color='r', linestyle='--', alpha=0.5)\n",
        "plt.axhline(y=30, color='r', linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(df.index, df['MACD'])\n",
        "plt.title('MACD')\n",
        "plt.ylabel('MACD')\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(df.index, df['Volume'])\n",
        "plt.title('Volume')\n",
        "plt.ylabel('Volume')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformerモデルの定義（Google Colab用）\n",
        "def create_transformer_model(input_dim, num_heads=8, ff_dim=32, num_layers=2, dropout_rate=0.1):\n",
        "    \"\"\"\n",
        "    Transformerモデルを作成\n",
        "    \n",
        "    Args:\n",
        "        input_dim: 入力次元数\n",
        "        num_heads: マルチヘッドアテンションのヘッド数\n",
        "        ff_dim: フィードフォワード層の次元数\n",
        "        num_layers: Transformerレイヤーの数\n",
        "        dropout_rate: ドロップアウト率\n",
        "    \n",
        "    Returns:\n",
        "        Kerasモデル\n",
        "    \"\"\"\n",
        "    inputs = Input(shape=(1, input_dim))\n",
        "    \n",
        "    # Transformerブロック\n",
        "    x = inputs\n",
        "    for _ in range(num_layers):\n",
        "        # Multi-Head Attention\n",
        "        attention_output = MultiHeadAttention(\n",
        "            num_heads=num_heads, \n",
        "            key_dim=input_dim // num_heads\n",
        "        )(x, x)\n",
        "        attention_output = Dropout(dropout_rate)(attention_output)\n",
        "        x = LayerNormalization(epsilon=1e-6)(x + attention_output)\n",
        "        \n",
        "        # Feed Forward\n",
        "        ffn_output = Dense(ff_dim, activation=\"relu\")(x)\n",
        "        ffn_output = Dense(input_dim)(ffn_output)\n",
        "        ffn_output = Dropout(dropout_rate)(ffn_output)\n",
        "        x = LayerNormalization(epsilon=1e-6)(x + ffn_output)\n",
        "    \n",
        "    # Global Average Pooling\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    \n",
        "    # 出力層\n",
        "    x = Dense(64, activation=\"relu\")(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "print(\"Transformerモデル定義完了\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データの前処理\n",
        "print(\"データの前処理開始...\")\n",
        "preprocessor = DataPreprocessor(scaler_type='standard')\n",
        "X_scaled, y = preprocessor.fit_transform(df, target_column='Close')\n",
        "\n",
        "# 最後の行は予測対象なので除外\n",
        "X_scaled = X_scaled[:-1]\n",
        "y = y[:-1]\n",
        "\n",
        "print(f\"特徴量数: {X_scaled.shape[1]}\")\n",
        "print(f\"データ数: {X_scaled.shape[0]}\")\n",
        "print(f\"ターゲット分布: {np.bincount(y)}\")\n",
        "\n",
        "# 学習・テストデータの分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Transformerモデル用にデータを3次元に変換\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "\n",
        "print(f\"訓練データ: {X_train.shape}\")\n",
        "print(f\"テストデータ: {X_test.shape}\")\n",
        "\n",
        "# GPU使用状況の確認\n",
        "print(f\"\\nGPU使用可能: {tf.config.list_physical_devices('GPU')}\")\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"✅ GPUが使用可能です\")\n",
        "else:\n",
        "    print(\"⚠️ CPUで実行されます\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# モデルの作成とコンパイル\n",
        "print(\"モデルの作成とコンパイル...\")\n",
        "model = create_transformer_model(input_dim=X_train.shape[2])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# モデルの概要を表示\n",
        "model.summary()\n",
        "\n",
        "# Google Colabでの訓練進捗を監視するコールバック\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Google Driveにモデルを保存するパス\n",
        "checkpoint_path = \"/content/drive/MyDrive/transformer_model_checkpoint.h5\"\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        checkpoint_path,\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        mode='max',\n",
        "        verbose=1\n",
        "    ),\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "print(\"モデル準備完了\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# モデルの訓練開始\n",
        "print(\"🚀 モデル訓練を開始します...\")\n",
        "print(\"⏱️ 訓練時間は約15-30分程度を予想しています\")\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,  # 多めに設定（EarlyStoppingで自動停止）\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "print(f\"✅ 訓練完了！\")\n",
        "print(f\"⏱️ 訓練時間: {training_time/60:.1f}分\")\n",
        "\n",
        "# 訓練結果の可視化\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss', alpha=0.8)\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', alpha=0.8)\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy', alpha=0.8)\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', alpha=0.8)\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(history.history['lr'] if 'lr' in history.history else [], label='Learning Rate', alpha=0.8)\n",
        "plt.title('Learning Rate')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# モデルの評価と保存\n",
        "print(\"📊 モデルの評価中...\")\n",
        "\n",
        "# テストデータでの評価\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"✅ テスト精度: {test_accuracy:.4f}\")\n",
        "print(f\"📉 テスト損失: {test_loss:.4f}\")\n",
        "\n",
        "# 予測結果の詳細分析\n",
        "y_pred = model.predict(X_test, verbose=0)\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(\"\\n📋 分類レポート:\")\n",
        "print(classification_report(y_test, y_pred_binary))\n",
        "\n",
        "print(\"\\n🎯 混同行列:\")\n",
        "cm = confusion_matrix(y_test, y_pred_binary)\n",
        "print(cm)\n",
        "\n",
        "# 混同行列の可視化\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "classes = ['下落', '上昇']\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes)\n",
        "plt.yticks(tick_marks, classes)\n",
        "\n",
        "# 数値を表示\n",
        "thresh = cm.max() / 2.\n",
        "for i, j in np.ndindex(cm.shape):\n",
        "    plt.text(j, i, format(cm[i, j], 'd'),\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.ylabel('実際のラベル')\n",
        "plt.xlabel('予測ラベル')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Google Driveにモデルとスケーラーを保存\n",
        "final_model_path = \"/content/drive/MyDrive/transformer_model_final.h5\"\n",
        "scaler_path = \"/content/drive/MyDrive/scaler.pkl\"\n",
        "\n",
        "model.save(final_model_path)\n",
        "preprocessor.save_scaler(scaler_path)\n",
        "\n",
        "print(f\"💾 最終モデルを保存: {final_model_path}\")\n",
        "print(f\"💾 スケーラーを保存: {scaler_path}\")\n",
        "\n",
        "# 訓練サマリーの保存\n",
        "import json\n",
        "training_summary = {\n",
        "    'symbol': symbol,\n",
        "    'timeframe': timeframe,\n",
        "    'data_points': len(data),\n",
        "    'features': X_train.shape[2],\n",
        "    'training_time_minutes': training_time/60,\n",
        "    'final_accuracy': float(test_accuracy),\n",
        "    'final_loss': float(test_loss),\n",
        "    'epochs_trained': len(history.history['loss'])\n",
        "}\n",
        "\n",
        "with open(\"/content/drive/MyDrive/training_summary.json\", \"w\") as f:\n",
        "    json.dump(training_summary, f, indent=2)\n",
        "\n",
        "print(\"📝 訓練サマリーを保存しました\")\n",
        "print(\"\\n🎉 全ての処理が完了しました！\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
