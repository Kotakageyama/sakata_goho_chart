{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Transformer Model Training\n",
        "## 暗号通貨価格予測のためのTransformerモデルトレーニング\n",
        "\n",
        "このNotebookでは、暗号通貨の価格予測のためのTransformerモデルを訓練します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 必要なライブラリのインポート\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('../../')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# 自作モジュールのインポート\n",
        "from src.data_fetcher import DataFetcher\n",
        "from src.technical_indicators import TechnicalIndicators\n",
        "from src.utils import DataPreprocessor, ModelUtils\n",
        "\n",
        "# Transformerモデル用のライブラリ\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LayerNormalization, Dropout\n",
        "from tensorflow.keras.layers import MultiHeadAttention, GlobalAveragePooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データ取得\n",
        "# 注意: 実際のAPIキーは別途設定してください\n",
        "# from google.colab import userdata  # Google Colab使用時\n",
        "# api_key = userdata.get('KuCoin_API_KEY')\n",
        "# secret = userdata.get('KuCoin_API_SECRET')\n",
        "# password = userdata.get('KuCoin_API_PASSPHRAS')\n",
        "\n",
        "# テスト用のダミーデータフェッチャー（実際は上記のAPIキーを使用）\n",
        "fetcher = DataFetcher('kucoin')\n",
        "\n",
        "# データ取得設定\n",
        "symbol = 'SOL/USDT'\n",
        "timeframe = '1d'\n",
        "limit = 8760 * 2  # 2年分\n",
        "\n",
        "print(f\"データ取得開始: {symbol}\")\n",
        "# data = fetcher.fetch_ohlcv_data(symbol, timeframe, limit)\n",
        "# print(f\"取得完了: {len(data)}件\")\n",
        "\n",
        "# 実際のAPIキーが設定されていない場合のダミーデータ\n",
        "np.random.seed(42)\n",
        "dates = pd.date_range(start='2022-01-01', periods=1000, freq='D')\n",
        "data = pd.DataFrame({\n",
        "    'Open': np.random.randn(1000).cumsum() + 100,\n",
        "    'High': np.random.randn(1000).cumsum() + 102,\n",
        "    'Low': np.random.randn(1000).cumsum() + 98,\n",
        "    'Close': np.random.randn(1000).cumsum() + 100,\n",
        "    'Volume': np.random.randn(1000).cumsum() + 1000000\n",
        "}, index=dates)\n",
        "\n",
        "# 価格の整合性を確保\n",
        "for i in range(len(data)):\n",
        "    data.iloc[i, 1] = max(data.iloc[i, [0, 1, 2, 3]])  # High\n",
        "    data.iloc[i, 2] = min(data.iloc[i, [0, 1, 2, 3]])  # Low\n",
        "\n",
        "print(f\"データ準備完了: {len(data)}件\")\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# テクニカル指標の追加\n",
        "print(\"テクニカル指標を計算中...\")\n",
        "df = TechnicalIndicators.add_all_indicators(data)\n",
        "print(f\"テクニカル指標追加完了: {df.shape}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformerモデルの定義\n",
        "def create_transformer_model(input_dim, num_heads=8, ff_dim=32, num_layers=2, dropout_rate=0.1):\n",
        "    \"\"\"\n",
        "    Transformerモデルを作成\n",
        "    \n",
        "    Args:\n",
        "        input_dim: 入力次元数\n",
        "        num_heads: マルチヘッドアテンションのヘッド数\n",
        "        ff_dim: フィードフォワード層の次元数\n",
        "        num_layers: Transformerレイヤーの数\n",
        "        dropout_rate: ドロップアウト率\n",
        "    \n",
        "    Returns:\n",
        "        Kerasモデル\n",
        "    \"\"\"\n",
        "    inputs = Input(shape=(1, input_dim))\n",
        "    \n",
        "    # Transformerブロック\n",
        "    x = inputs\n",
        "    for _ in range(num_layers):\n",
        "        # Multi-Head Attention\n",
        "        attention_output = MultiHeadAttention(\n",
        "            num_heads=num_heads, \n",
        "            key_dim=input_dim // num_heads\n",
        "        )(x, x)\n",
        "        attention_output = Dropout(dropout_rate)(attention_output)\n",
        "        x = LayerNormalization(epsilon=1e-6)(x + attention_output)\n",
        "        \n",
        "        # Feed Forward\n",
        "        ffn_output = Dense(ff_dim, activation=\"relu\")(x)\n",
        "        ffn_output = Dense(input_dim)(ffn_output)\n",
        "        ffn_output = Dropout(dropout_rate)(ffn_output)\n",
        "        x = LayerNormalization(epsilon=1e-6)(x + ffn_output)\n",
        "    \n",
        "    # Global Average Pooling\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    \n",
        "    # 出力層\n",
        "    x = Dense(64, activation=\"relu\")(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データの前処理\n",
        "preprocessor = DataPreprocessor(scaler_type='standard')\n",
        "X_scaled, y = preprocessor.fit_transform(df, target_column='Close')\n",
        "\n",
        "# 最後の行は予測対象なので除外\n",
        "X_scaled = X_scaled[:-1]\n",
        "y = y[:-1]\n",
        "\n",
        "print(f\"特徴量数: {X_scaled.shape[1]}\")\n",
        "print(f\"データ数: {X_scaled.shape[0]}\")\n",
        "print(f\"ターゲット分布: {np.bincount(y)}\")\n",
        "\n",
        "# 学習・テストデータの分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Transformerモデル用にデータを3次元に変換\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "\n",
        "print(f\"訓練データ: {X_train.shape}\")\n",
        "print(f\"テストデータ: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# モデルの作成とコンパイル\n",
        "model = create_transformer_model(input_dim=X_train.shape[2])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# モデルの概要を表示\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# モデルの訓練\n",
        "print(\"モデル訓練を開始...\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 訓練結果の可視化\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# モデルの保存\n",
        "model_save_path = \"../../models/transformer_model.h5\"\n",
        "scaler_save_path = \"../../models/scaler.pkl\"\n",
        "\n",
        "ModelUtils.save_model(model, model_save_path)\n",
        "preprocessor.save_scaler(scaler_save_path)\n",
        "\n",
        "print(\"モデルとスケーラーを保存しました\")\n",
        "\n",
        "# テストデータでの評価\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"テスト精度: {test_accuracy:.4f}\")\n",
        "print(f\"テスト損失: {test_loss:.4f}\")\n",
        "\n",
        "# 予測結果の確認\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(\"\\n分類レポート:\")\n",
        "print(classification_report(y_test, y_pred_binary))\n",
        "print(\"\\n混同行列:\")\n",
        "print(confusion_matrix(y_test, y_pred_binary))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
